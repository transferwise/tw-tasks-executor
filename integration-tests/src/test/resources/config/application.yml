spring:
  kafka:
    bootstrap-servers: ${TW-TASKS-EXECUTOR-KAFKA_HOST:localhost}:${TW-TASKS-EXECUTOR-KAFKA_TCP_9092}
    properties:
      max.request.size: 10000012
      request.timeout.ms: 11000
      session.timeout.ms: 10000
      max.partition.fetch.bytes: 10485760
      partitioner.class: org.apache.kafka.clients.producer.RoundRobinPartitioner
    producer:
      acks: 'all'
    consumer:
      maxPollRecords: 10
      autoOffsetReset: 'earliest'
      enableAutoCommit: false
      heartbeatInterval: PT1S

tw-tasks:
  core:
    zookeeper-connect-string: ${ZOOKEEPER_HOST:localhost}:${ZOOKEEPER_TCP_2181}
    topic-replication-factor: 1
    waiting-tasks-polling-interval: PT0.1S
    additional-processing-buckets: manualStart
    stuck-tasks-polling-interval: PT1S
    generic-medium-delay: 100ms
    taskTablesSchemaName: "tw-tasks-test"
    assertionsEnabled: true
    compression:
      algorithm: random
      minSize: 0 # Pretty much forcing compression to always happen, so it will be tested through
    environment:
      previousVersion: "1.21.1"
    triggering:
      kafka:
        bootstrap-servers: ${TW-TASKS-EXECUTOR-KAFKA_HOST:localhost}:${TW-TASKS-EXECUTOR-KAFKA_TCP_9092}
    tasks-management:
      type-specific:
        -
          task-type: "customType"
          view-task-data-roles:
            - ROLE_DEVEL
    triggers-commit-interval: 50ms

logging.level:
  com.transferwise.tasks: DEBUG
  com.transferwise.tasks.cleaning.TasksCleaner: INFO
  kafka: WARN
  org.apache.zookeeper: WARN
  com.transferwise.tasks.helpers.kafka.ConsistentKafkaConsumer: INFO

tw-graceful-shutdown:
  shutdown-timeout-ms: 1000
  clients-reaction-time-ms: 1
  strategies-check-interval-time-ms: 1000
tw-incidents:
  victorops:
    enabled: false
  slack:
    enabled: false
tw-curator:
  zookeeper-connect-string: ${ZOOKEEPER_HOST:localhost}:${ZOOKEEPER_TCP_2181}

---

tw-tasks:
  core:
    assert-status-on-grabbing: true
spring:
  config:
    activate:
      on-profile: continuous-integration
---

spring:
  datasource:
    url: jdbc:mariadb://${MARIADB_HOST:localhost}:${MARIADB_TCP_3306}/tw-tasks-test?rewriteBatchStatements=false
    username: root
    password: example-password-change-me
  kafka:
    client-id: test-mysql
    consumer:
      groupId: 'test-mysql'
  config:
    activate:
      on-profile: mysql

tw-tasks.core:
  db-type: mysql
  group-id: test-mysql
  client-id: test-mysql

spring.liquibase.change-log: classpath:db/changelog/db.tw-tasks-mysql.xml

---

spring:
  datasource:
    url: jdbc:postgresql://${POSTGRES_HOST:localhost}:${POSTGRES_TCP_5432}/postgres
    username: postgres
    password: example-password-change-me
  kafka:
    client-id: test-postgres
    consumer:
      groupId: 'test'
  config:
    activate:
      on-profile: postgres

tw-tasks.core:
  db-type: postgres
  group-id: test-postgres
  client-id: test-postgres
  taskTablesSchemaName: "public"

spring.liquibase.change-log: classpath:db/changelog/db.tw-tasks-postgres.xml

